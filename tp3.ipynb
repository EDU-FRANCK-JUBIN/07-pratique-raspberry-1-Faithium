{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/analytics-vidhya/traffic-signs-recognition-for-self-driving-cars-6ee30f5dc952\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "# Importing dataset\n",
    "import os\n",
    "data = []\n",
    "labels = []\n",
    "classes = 43\n",
    "cur_path = os.getcwd()\n",
    "for i in range(classes):\n",
    "    path = os.path.join(cur_path, 'Train', str(i))\n",
    "    images = os.listdir(path)\n",
    "    \n",
    "    for a in images:\n",
    "        try:\n",
    "            image = Image.open(path + '\\\\'+ a)\n",
    "            image = image.resize((30, 30))\n",
    "            image = np.array(image)\n",
    "            data.append(image)\n",
    "            labels.append(i)\n",
    "        except:\n",
    "            print(\"Error loading image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions :  (39209, 30, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Dataset dimensions : \",data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape :  (31367, 30, 30, 3)\n",
      "X_test shape :  (7842, 30, 30, 3)\n",
      "Y_train shape :  (31367,)\n",
      "Y_test shape :  (7842,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(\"X_train shape : \", X_train.shape)\n",
    "print(\"X_test shape : \", X_test.shape)\n",
    "print(\"Y_train shape : \", Y_train.shape)\n",
    "print(\"Y_test shape : \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "Y_train_categorical = to_categorical(Y_train, 43)\n",
    "Y_test_categorical = to_categorical(Y_test, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sign category : 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 100\n",
    "plt.imshow(X_train[i])\n",
    "print(\"Sign category :\",Y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        2432      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 22, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               147712    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 242,251\n",
      "Trainable params: 242,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5, 5), activation = 'relu', input_shape = X_train.shape[1:]))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5, 5), activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(rate = 0.25))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(rate = 0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dropout(rate = 0.5))\n",
    "model.add(Dense(43, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31367 samples, validate on 7842 samples\n",
      "Epoch 1/15\n",
      "31367/31367 [==============================] - 90s 3ms/step - loss: 1.1049 - accuracy: 0.6920 - val_loss: 0.3217 - val_accuracy: 0.9132\n",
      "Epoch 2/15\n",
      "31367/31367 [==============================] - 81s 3ms/step - loss: 0.4875 - accuracy: 0.8594 - val_loss: 0.2164 - val_accuracy: 0.9411\n",
      "Epoch 3/15\n",
      "31367/31367 [==============================] - 78s 2ms/step - loss: 0.3787 - accuracy: 0.8951 - val_loss: 0.1983 - val_accuracy: 0.9537\n",
      "Epoch 4/15\n",
      "31367/31367 [==============================] - 77s 2ms/step - loss: 0.3350 - accuracy: 0.9054 - val_loss: 0.1457 - val_accuracy: 0.9605\n",
      "Epoch 5/15\n",
      "31367/31367 [==============================] - 82s 3ms/step - loss: 0.3115 - accuracy: 0.9108 - val_loss: 0.1493 - val_accuracy: 0.9535\n",
      "Epoch 6/15\n",
      "31367/31367 [==============================] - 79s 3ms/step - loss: 0.3034 - accuracy: 0.9135 - val_loss: 0.1619 - val_accuracy: 0.9498\n",
      "Epoch 7/15\n",
      "31367/31367 [==============================] - 80s 3ms/step - loss: 0.2874 - accuracy: 0.9204 - val_loss: 0.1061 - val_accuracy: 0.9726\n",
      "Epoch 8/15\n",
      "31367/31367 [==============================] - 88s 3ms/step - loss: 0.2844 - accuracy: 0.9225 - val_loss: 0.0958 - val_accuracy: 0.9723\n",
      "Epoch 9/15\n",
      "31367/31367 [==============================] - 75s 2ms/step - loss: 0.2832 - accuracy: 0.9208 - val_loss: 0.1689 - val_accuracy: 0.9495\n",
      "Epoch 10/15\n",
      "31367/31367 [==============================] - 76s 2ms/step - loss: 0.2603 - accuracy: 0.9290 - val_loss: 0.1196 - val_accuracy: 0.9649\n",
      "Epoch 11/15\n",
      "31367/31367 [==============================] - 76s 2ms/step - loss: 0.2597 - accuracy: 0.9296 - val_loss: 0.0807 - val_accuracy: 0.9764\n",
      "Epoch 12/15\n",
      "31367/31367 [==============================] - 76s 2ms/step - loss: 0.2678 - accuracy: 0.9300 - val_loss: 0.1783 - val_accuracy: 0.9475\n",
      "Epoch 13/15\n",
      "31367/31367 [==============================] - 854s 27ms/step - loss: 0.2604 - accuracy: 0.9299 - val_loss: 0.1687 - val_accuracy: 0.9508\n",
      "Epoch 14/15\n",
      "31367/31367 [==============================] - 81s 3ms/step - loss: 0.2664 - accuracy: 0.9299 - val_loss: 0.0995 - val_accuracy: 0.9735\n",
      "Epoch 15/15\n",
      "31367/31367 [==============================] - 103s 3ms/step - loss: 0.2342 - accuracy: 0.9376 - val_loss: 0.0633 - val_accuracy: 0.9819\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, Y_train_categorical, batch_size = 32, epochs = 15, validation_data = (X_test, Y_test_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-a89cd35ef256>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'training accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['acc'], label='training accuracy')\n",
    "plt.plot(history.history['val_acc'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_test = pd.read_csv('Test.csv')\n",
    "labels = y_test[\"ClassId\"].values\n",
    "imgs = y_test[\"Path\"].values\n",
    "\n",
    "data = []\n",
    "\n",
    "for img in imgs:\n",
    "    image = Image.open(img)\n",
    "    image = image.resize((30,30))\n",
    "    data.append(np.array(image))\n",
    "\n",
    "X_test = np.array(data)\n",
    "\n",
    "pred = model.predict_classes(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy Score : \",accuracy_score(labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
